{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIA5FNbEq8by",
    "outputId": "7d191c03-a091-49b1-bd59-1ff673cec394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Sastrawi\n",
      "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m204.8/209.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Sastrawi\n",
      "Successfully installed Sastrawi-1.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install Sastrawi\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    factory = StopWordRemoverFactory()\n",
    "    stopwords = factory.get_stop_words()\n",
    "\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "\n",
    "    return filtered_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0cNmwuSVHfsM"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def fix_word(text):\n",
    "    return ' '.join([kamus_dict[word] if word in kamus_dict else word for word in text.split(' ')])\n",
    "\n",
    "def remove_unnecessaryChar(text):\n",
    "     text = re.sub(r'&amp;|amp;|&', 'dan', text)\n",
    "     text = re.sub(r'\\\\n+', '', text)\n",
    "     text = re.sub('&lt;/?[a-z]+&gt;', ' ', text)\n",
    "     text = re.sub(r'#+','#', text)\n",
    "     text = re.sub(r'http\\S+',' ',text)\n",
    "     text = re.sub(r'(USER+\\s?|RT+\\s?|URL+\\s?)', ' ', text)\n",
    "     text = re.sub(r'x[a-zA-Z0-9]+', ' ', text)\n",
    "     return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "     text = re.sub(r'\\?', '', text)\n",
    "     text = re.sub(r'[^a-zA-Z0-9]+', ' ', text)\n",
    "     text = re.sub(r' +', ' ', text.lower().lstrip(\"0123456789\").strip())\n",
    "     return text\n",
    "\n",
    "def preprocessing(text):\n",
    "     text = remove_unnecessaryChar(text)\n",
    "     text = remove_punctuation(text)\n",
    "     text = fix_word(text)\n",
    "     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QxTKICj5HkRm",
    "outputId": "3eee697d-4de6-455c-f115-d58ac114f12a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c439dcd8-939a-4775-b95a-db8e8691e7d2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung dimiliki pengusaha pabrik tahu puluhan ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus k212 mmbri hujjah partai apa...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis jalan sumatra bandung tempat ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri unbo paket barang nya ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aduh jadi mahasiswa jangan sombong dong kasih ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c439dcd8-939a-4775-b95a-db8e8691e7d2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c439dcd8-939a-4775-b95a-db8e8691e7d2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c439dcd8-939a-4775-b95a-db8e8691e7d2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  warung dimiliki pengusaha pabrik tahu puluhan ...  positive\n",
       "1  mohon ulama lurus k212 mmbri hujjah partai apa...   neutral\n",
       "2  lokasi strategis jalan sumatra bandung tempat ...  positive\n",
       "3  betapa bahagia nya diri unbo paket barang nya ...  positive\n",
       "4  aduh jadi mahasiswa jangan sombong dong kasih ...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train_preprocess.tsv.txt', encoding='ISO-8859-1', delimiter=\"\\t\", names=['text','sentiment'])\n",
    "df[\"text\"] = df[\"text\"].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "df.drop_duplicates()\n",
    "# print(df.head(30))\n",
    "kamus = pd.read_csv('new_kamusalay.csv', names=['old','new'], encoding='ISO-8859-1')\n",
    "kamus_dict = dict(zip(kamus['old'], kamus['new']))\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(remove_stopwords2)# remove stopwords\n",
    "df[\"text\"] = df[\"text\"].apply(preprocessing)# apply cleansing\n",
    "\n",
    "df.replace('', pd.NA, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "id": "QJYXpDuY04_X",
    "outputId": "55a9a4a4-01ec-45ad-e195-4b0f6768fa70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(37,), max_iter=2000,\n",
       "              random_state=27)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(37,), max_iter=2000,\n",
       "              random_state=27)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=(37,), max_iter=2000,\n",
       "              random_state=27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# endocde sentiment\n",
    "le = LabelEncoder()\n",
    "df['sentiment_encoded'] = le.fit_transform(df['sentiment'])\n",
    "\n",
    "# split dataset\n",
    "X = df['text']\n",
    "y = df['sentiment_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)\n",
    "\n",
    "# feature extraction\n",
    "vectorizer = CountVectorizer()  # Bag of Words\n",
    "# vectorizer = TfidfVectorizer()  # TF-IDF\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "X_test_features = vectorizer.transform(X_test)\n",
    "\n",
    "# NN classifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(37,), solver=\"adam\", activation=\"relu\", early_stopping=True, max_iter=2000, random_state=27)\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(10), (25), (37), (50,),(75), (100,), (150,)],\n",
    "#     'activation': ['relu', 'tanh', 'logistic', 'identity'],\n",
    "#     'solver': ['adam', 'sgd', 'lbfgs']\n",
    "# }\n",
    "\n",
    "# Create the MLPClassifier model\n",
    "# classifier = MLPClassifier(random_state=27, max_iter=2000)\n",
    "\n",
    "# Perform grid search\n",
    "# grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
    "# grid_search.fit(X_train_features, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n",
    "# print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "\n",
    "# Cross-validation\n",
    "# cv_scores = cross_val_score(classifier, X_train_features, y_train, cv=5)\n",
    "\n",
    "# print(\"Cross-validation scores:\", cv_scores)\n",
    "# print(\"Mean cross-validation score:\", cv_scores.mean())\n",
    "\n",
    "# Train\n",
    "classifier.fit(X_train_features, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zsci0pU4rZQ",
    "outputId": "f9dce5d6-35bf-44df-f0c8-69f909110fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8759090909090909\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83       678\n",
      "     neutral       0.88      0.72      0.79       236\n",
      "    positive       0.91      0.92      0.91      1286\n",
      "\n",
      "    accuracy                           0.88      2200\n",
      "   macro avg       0.87      0.83      0.85      2200\n",
      "weighted avg       0.88      0.88      0.88      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "y_pred = classifier.predict(X_test_features)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names=le.classes_)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zOCc2bCM47J8",
    "outputId": "3c899894-b133-443e-e866-aa638a53dedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0]\n",
      "Predicted Sentiments: ['positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "new_texts = [\"Aku suka banget dengan movie tadi malam\", \"Pertandingan kemarin rusuh banget\"]\n",
    "new_texts_features = vectorizer.transform(new_texts)\n",
    "new_sentiments_encoded = classifier.predict(new_texts_features)\n",
    "print(new_sentiments_encoded)\n",
    "new_sentiments = le.inverse_transform(new_sentiments_encoded)\n",
    "print(\"Predicted Sentiments:\", new_sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AiGn33aj4Unh"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Save the trained model, countVectorizer, label encoder to a file\n",
    "with open('modelnn.pkl', 'wb') as file:\n",
    "    pickle.dump(classifier, file)\n",
    "\n",
    "with open('vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "with open('labelencoder.pkl', 'wb') as file:\n",
    "    pickle.dump(le, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlZi0QrXPGWt"
   },
   "outputs": [],
   "source": [
    "alay_df = pd.read_csv(\"new_kamusalay.csv\", usecols=[0, 1], names=[\n",
    "                      'alay', 'baku'], header=None, encoding='latin-1')\n",
    "\n",
    "def clean_text(sentence):\n",
    "    words = sentence.split()\n",
    "    clean_words = []\n",
    "    for word in words:\n",
    "        if word in alay_df[\"alay\"].tolist():\n",
    "            standard_word = alay_df.loc[alay_df[\"alay\"]\n",
    "                                        == word, \"baku\"].iloc[0]\n",
    "            clean_words.append(standard_word)\n",
    "        else:\n",
    "            clean_words.append(word)\n",
    "\n",
    "    clean_sentence = \" \".join(clean_words)\n",
    "    return clean_sentence\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YD8m0tGUM9w1",
    "outputId": "c784af68-f521-40c9-cf7c-04444ad1aba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   tweet sentiment\n",
      "0      di saat semua cowok berusaha melacak perhatian...  negative\n",
      "1      siapa telat memberi tau eluedan sarap gue berg...  negative\n",
      "2      kadang aku berpikir aku tetap percaya tuhan pa...  positive\n",
      "3            aku akuku tau matamu sipit dilihat mana aku  negative\n",
      "4      kaum cebong kafir sudah kelihatan dongoknya aw...  negative\n",
      "...                                                  ...       ...\n",
      "13164  jangan asal berbicara ndasmu congor kamu yang ...  negative\n",
      "13165                             kasur mana enak kunyuk  negative\n",
      "13166                    hati hati bisu glagi bosan aduh  negative\n",
      "13167  bom real mudah terdeteksi bom terkubur suatu l...   neutral\n",
      "13168             mana situ memberi cuma foto kutil onta  negative\n",
      "\n",
      "[13169 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data = pd.read_csv('data.csv',encoding=\"latin-1\")\n",
    "\n",
    "# Preprocess the data\n",
    "data[\"Tweet\"] = data[\"Tweet\"].apply(remove_stopwords2)# remove stopwords\n",
    "data[\"Tweet\"] = data[\"Tweet\"].apply(preprocessing)# apply cleansing\n",
    "data[\"Tweet\"] = data[\"Tweet\"].apply(clean_text)# apply cleansing alay\n",
    "\n",
    "X = data['Tweet'].astype(str)\n",
    "\n",
    "# Transform the data using the trained vectorizer\n",
    "X_test_vec = vectorizer.transform(X)\n",
    "\n",
    "# Predict the sentiment for the \"tweet\" column\n",
    "predictions = classifier.predict(X_test_vec)\n",
    "predictions = le.inverse_transform(predictions)\n",
    "\n",
    "# Create a new DataFrame with the original data and the predictions\n",
    "output = pd.DataFrame({'tweet': X, 'sentiment': predictions})\n",
    "\n",
    "# Save the DataFrame to a new CSV file\n",
    "# output.to_csv('predictions.csv', index=False)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
